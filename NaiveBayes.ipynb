{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNZxqeXQL65rmnfnKAvJ+4Q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","import random\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import StandardScaler\n","import tensorflow as tf\n","from tensorflow import keras\n","import pandas as pd\n","import json"],"metadata":{"id":"H5SyV3-hFUv6","executionInfo":{"status":"ok","timestamp":1663263424143,"user_tz":360,"elapsed":306,"user":{"displayName":"Daniel Igbokwe","userId":"05432804126026323217"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# Naive Bayes classifier\n"," Only accepts discrete data as features and labels  "],"metadata":{"id":"X8w_hFqBE_1E"}},{"cell_type":"code","execution_count":3,"metadata":{"id":"gZAPtn8yDWhz","executionInfo":{"status":"ok","timestamp":1663263074658,"user_tz":360,"elapsed":380,"user":{"displayName":"Daniel Igbokwe","userId":"05432804126026323217"}}},"outputs":[],"source":["\n","class NaiveBayes:\n","\n","    def __init__(self):\n","        self.probabilities = {}\n","        self.unique_labels = []\n","\n","    def evaluate(self, features, labels):\n","      return self.predict(features, labels)\n","\n","    def predict(self, features, labels=None):\n","        predictions_prob = []\n","        predictions = []\n","\n","        for instance in features:\n","            predicted = self.probabilities[len(self.probabilities) - 1]\n","            for i, feature in enumerate(instance):\n","                dictionary = self.probabilities[i]\n","                if feature in dictionary.keys():\n","                    predicted = np.multiply(dictionary[feature], predicted)\n","            # print(predicted)\n","            # renormalize \n","            for i in range(len(predicted)):\n","                predicted[i] = predicted[i] / np.sum(predicted)\n","            predictions_prob.append(predicted) #\n","\n","        for i in range(len(predictions_prob)):\n","                predictions.append(np.argmax(predictions_prob[i])) \n","\n","        if labels is not None:\n","            accuracy = 0\n","            for prediction, target in zip(predictions, labels):\n","                if self.unique_labels[prediction] == target:\n","                    accuracy += 1\n","\n","            accuracy = accuracy / len(predictions_prob)\n","            loss = 1 - accuracy\n","\n","            return accuracy, loss\n","        # else:\n","        #     for i in range(len(predictions_prob)):\n","        #         predictions.append(np.argmax(predictions_prob[i]))\n","\n","        return predictions, predictions_prob\n","\n","    def _feature_prob(self, data):\n","        count = {}\n","        label_column = data[:, -1]\n","        for label in self.unique_labels:\n","            count[label] = 0\n","\n","        for target in label_column:\n","            for label in self.unique_labels:\n","                if target == label:\n","                    count[label] += 1\n","\n","        # if probability of a feature occuring in a label is 0\n","        # add 1 to all unique feature frequencey\n","        # prevents algorithm from always predicting 0\n","        # for missing class/ label \n","        if 0 in count.values():\n","          for label in self.unique_labels:\n","             count[label] += 1\n","\n","\n","       \n","\n","        return count\n","\n","    def _get_probability(self, data):\n","        prob = self._get_unique(data)[1] / len(data)\n","\n","        return prob\n","\n","    def _split(self, data, split_column, split_value):\n","        new_data = data[split_column == split_value]\n","        return new_data\n","\n","    # def _encode_class(self, labels):\n","    #     classes = self.unique_labels\n","\n","    #     label_dictionary = {}\n","    #     encoded_labels = []\n","\n","    #     for i in range(len(classes)):\n","    #         label_dictionary[classes[i]] = i\n","\n","    #     for i in range(len(labels)):\n","    #         encoded_labels.append( label_dictionary[labels[i]])\n","\n","    #     return encoded_labels\n","\n","    def train(self, features, labels):\n","        labels_reshaped = labels.reshape(labels.shape[0], -1)\n","        train_features = np.append(features, labels_reshaped, 1)\n","        self.probabilities = self._build_probabilities(train_features)\n","        accuracy, loss = self.evaluate(features, labels)\n","\n","        return accuracy, loss\n","\n","    def _get_unique(self, data):\n","        labels = data[:, -1]\n","        unique_values = np.unique(labels, return_counts=True)\n","\n","        return unique_values\n","\n","    def _build_probabilities(self, data):\n","        probabilities = {}\n","        for i in range(data.shape[1]):\n","            probabilities[i] = {}\n","        probabilities[data.shape[1] - 1] = self._get_probability(data)\n","        self.unique_labels, label_count = self._get_unique(data)\n","\n","        for i in range(data.shape[1] - 1):\n","            split_column = data[:, i]\n","            values = np.unique(split_column)\n","            for value in values:\n","                count = self._feature_prob(self._split(data, split_column, value))\n","\n","                value_probabilities = []\n","\n","                for j, elem in enumerate(self.unique_labels):\n","                    value_probabilities.append(count[elem] / label_count[j])\n","                probabilities[i][value] = value_probabilities\n","\n","        self.print_tree(probabilities)\n","\n","        return probabilities\n","\n","    def print_tree(self, data):\n","        print(json.dumps(data, indent=4, default=str))"]},{"cell_type":"code","source":[],"metadata":{"id":"J0iyJB2tLre2"},"execution_count":null,"outputs":[]}]}